{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../Dataset/\"\n",
    "files = os.listdir(dataset_dir)\n",
    "\n",
    "dataset_files = [ os.path.join(dataset_dir, file) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = {}\n",
    "for dataset_filename in dataset_files:\n",
    "    abc_notation_file = open(dataset_filename, 'r')\n",
    "    songs[os.path.basename(dataset_filename)] = abc_notation_file.read()\n",
    "    abc_notation_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File to train\n",
    "train_list = list(songs.keys())\n",
    "musical_train_file = train_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin training our RNN model, we'll need to create a numerical representation of our text-based dataset. To do this, we'll generate two lookup tables: one that maps characters to numbers, and a second that maps numbers back to characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 83 unique characters in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Find all unique characters in the joined string\n",
    "vocab = sorted(set(songs[musical_train_file]))\n",
    "print(\"There are\", len(vocab), \"unique characters in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from character to unique index.\n",
    "# For example, to get the index of the character \"d\", \n",
    "#   we can evaluate `char2idx[\"d\"]`.  \n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "\n",
    "# Create a mapping from indices to characters. This is\n",
    "#   the inverse of char2idx and allows us to convert back\n",
    "#   from unique index to the character in our vocabulary.\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  '\"' :   3,\n",
      "  '#' :   4,\n",
      "  \"'\" :   5,\n",
      "  '(' :   6,\n",
      "  ')' :   7,\n",
      "  ',' :   8,\n",
      "  '-' :   9,\n",
      "  '.' :  10,\n",
      "  '/' :  11,\n",
      "  '0' :  12,\n",
      "  '1' :  13,\n",
      "  '2' :  14,\n",
      "  '3' :  15,\n",
      "  '4' :  16,\n",
      "  '5' :  17,\n",
      "  '6' :  18,\n",
      "  '7' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_string(string):\n",
    "  vectorized_output = np.array([char2idx[char] for char in string])\n",
    "  return vectorized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49 22 14 ... 22 82  2]\n"
     ]
    }
   ],
   "source": [
    "print(vectorize_string(songs[musical_train_file]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200425\n",
      "200425\n"
     ]
    }
   ],
   "source": [
    "print(len(songs[musical_train_file]))\n",
    "print(len(vectorize_string(songs[musical_train_file])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicalDataset(torch.nn.Module):\n",
    "    def __init__(self, abc_string, seq_lenght):\n",
    "        self.dataset = abc_string\n",
    "        self.seq_lenght = seq_lenght\n",
    "\n",
    "        self.vocab = self.vocabulary(abc_string)\n",
    "        self.char2idx, self.idx2char = self.mapping(self.vocab)\n",
    "        self.vectorized_dataset = self.vectorize_string(self.dataset)\n",
    "    \n",
    "    def __len__(self):\n",
    "        '''\n",
    "            Why -1...?\n",
    "            Suppose seq_length is 4 and our text is \"Hello\". Then, our\n",
    "            input sequence (x) is \"Hell\" and the target sequence (y) is \"ello\".\n",
    "        '''\n",
    "        return len(self.dataset) - self.seq_lenght - 1\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.vectorized_dataset[idx : idx + self.seq_lenght]\n",
    "        y = self.vectorized_dataset[idx + 1 : idx + self.seq_lenght + 1]\n",
    "\n",
    "        return [torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)]\n",
    "    \n",
    "    def getVocabSize(self):\n",
    "        return len(self.vocab)\n",
    "    \n",
    "    def getSequenceLength(self):\n",
    "        return self.seq_lenght\n",
    "\n",
    "    def vectorize_string(self, string):\n",
    "        '''\n",
    "            Vectorize (convert to numerical) a string using the\n",
    "            mapping created by the notation presented in the dataset.\n",
    "            \n",
    "            @return a numpy array with `N` elements, where `N` is\n",
    "                the number of characters in the input string\n",
    "        '''\n",
    "        return np.array([self.char2idx[char] for char in string])\n",
    "    \n",
    "    def vocabulary(self, string):\n",
    "        '''\n",
    "            Return the vocabulary used in the input string, i.e\n",
    "            a set of no duplicated elements.\n",
    "            \n",
    "            @param string: the dataset with several songs written using\n",
    "                a specific anotation\n",
    "        '''\n",
    "        return sorted(set(string))\n",
    "    \n",
    "    def mapping(self, vocab):\n",
    "        '''\n",
    "         Create a mapping from character to unique index and from \n",
    "         indices to characters. \n",
    "         \n",
    "         @param vocab: A set with no duplicate elements which represents\n",
    "             the vocabulary of our anotation (all unique characters).\n",
    "         @return Mapping contained in a list [char2idx, idx2char]        \n",
    "        '''\n",
    "        char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "        idx2char = np.array(vocab)\n",
    "        \n",
    "        return [char2idx, idx2char]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = MusicalDataset(songs[musical_train_file], 8)\n",
    "print(len(test))\n",
    "\n",
    "dataloader = DataLoader(test, batch_size=2, shuffle=False, num_workers=4)\n",
    "print(len(dataloader))\n",
    "\n",
    "idx = 0\n",
    "for inputs, targets in dataloader:\n",
    "    idx += 1\n",
    "\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dataloader))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Recurrent Neural Network (RNN) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is based off the LSTM architecture, where we use a state vector to maintain information about the temporal relationships between consecutive characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/aamini/introtodeeplearning/2019/lab1/img/lstm_unrolled-01-01.png\" alt=\"Drawing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesante añadir una descripción del funcionamiento de los *emmbeding layers* para que quede claro su funcionamiento. \n",
    "\n",
    "Arreglar la imagen para que quede más explicito las dimensiones entre capas.\n",
    "\n",
    "Añadir los detalles de los pasos del LSTM: olvidar, añadir..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicalLSTMModel(torch.nn.Module):\n",
    "    '''Container module with an encoder, a recurrent module, and a decoder.'''\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_state_dim, rnn_units, dropout=0.05):\n",
    "        super(MusicalLSTMModel, self).__init__()\n",
    "\n",
    "        self.encoder = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = torch.nn.LSTM(embedding_dim, hidden_state_dim, rnn_units, \\\n",
    "                                 dropout=dropout, batch_first=True)\n",
    "        self.decoder = torch.nn.Linear(hidden_state_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        emb = self.encoder(x) # (batch_size, sequence_length, embedding_dim)\n",
    "        output, hidden = self.rnn(emb) # (batch_size, sequence_length, hidden_size)\n",
    "        \n",
    "        output = self.reshapeLSTMOutput(output) # (batch_size*sequence_length, hidden_size)\n",
    "               \n",
    "        output = self.decoder(output) # (batch_size*sequence_length, vocab_size)\n",
    "        return output, hidden\n",
    "    \n",
    "    def reshapeLSTMOutput(self, lstm_output):\n",
    "        '''\n",
    "            This function reshapes the LSTM output in order to be able\n",
    "            to use in the following layer, nn.Linear() layer.\n",
    "            \n",
    "            \n",
    "            @param lstm_output: tensor output from LSTM layer shich shape is \n",
    "                (batch_size, sequence_length, hidden_size) \n",
    "                \n",
    "            @result: Reshape output to (batch_size*sequence_length, hidden_size)\n",
    "        '''\n",
    "        batch_size = lstm_output.size(0) * lstm_output.size(1)\n",
    "        hidden_size = lstm_output.size(2)\n",
    "        return lstm_output.reshape(batch_size, hidden_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "seq_length = num_layers = 8\n",
    "hidden_size = 512\n",
    "vocab_size = 3\n",
    "learning_rate = 5e-2\n",
    "seq_length = 100\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = MusicalDataset(songs[musical_train_file], seq_lenght=seq_length)\n",
    "\n",
    "model = MusicalLSTMModel(dataset.getVocabSize(), embedding_dim=256, hidden_state_dim=hidden_size, \\\n",
    "                         rnn_units=dataset.getSequenceLength()).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = ((vocab_size) * torch.rand(batch_size, seq_length)).type(torch.long)\n",
    "states = (torch.zeros(num_layers, batch_size, hidden_size),\n",
    "          torch.zeros(num_layers, batch_size, hidden_size))\n",
    "\n",
    "print(\"Input shape:      \", input.shape, \" # (batch_size, sequence_length)\")\n",
    "pred, hidden = model(input, states)\n",
    "\n",
    "print(\"Prediction shape: \", pred.shape, \"# (batch_size * sequence_length, vocab_size)\")\n",
    "print(\"Hidden shape: \", hidden[0].shape, \"# (num_layers, batch_size, vocab_size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/02-intermediate/language_model/main.py\n",
    "\n",
    "¿Por qué el detach del estado?\n",
    "https://discuss.pytorch.org/t/solved-why-we-need-to-detach-variable-which-contains-hidden-representation/1426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, batch_size, optimizer, n_epochs=25, writer=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "    seq_length = num_layers = dataset.getSequenceLength()\n",
    "    \n",
    "    # Lambda function to detach the hidden state from t-1, It has to be considered\n",
    "    # as constant\n",
    "    detach = lambda states : [state.detach() for state in states]\n",
    "    \n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        # Set initial hidden and cell states\n",
    "        states = (torch.zeros(num_layers, batch_size, hidden_size).to(device),\n",
    "                  torch.zeros(num_layers, batch_size, hidden_size).to(device))\n",
    "        \n",
    "        # statistics\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for idx, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = inputs.to(device)\n",
    "            \n",
    "            states = detach(states)\n",
    "            outputs, states = model(inputs, states)\n",
    "            loss = criterion(outputs, targets.reshape(-1))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "        \n",
    "            step = (idx+1) // seq_length\n",
    "            if step % 10000000000 == 0:\n",
    "                if writer:\n",
    "                    writer.add_scalar('Train/Iterative_Loss', loss.item(), idx)\n",
    "            \n",
    "            running_loss +=  loss.item() * inputs.size(0)\n",
    "#             step = (idx+1) // seq_length\n",
    "#             if step % 10000 == 0:\n",
    "#                 print ('Epoch [{}/{}], Step[{}/{}], Loss: {:.4f}, Perplexity: {:5.2f}'\n",
    "#                        .format(epoch+1, n_epochs, step, batch_size, loss.item(), np.exp(loss.item())))\n",
    "                \n",
    "        epoch_loss = running_loss / len(dataset)\n",
    "        if writer:\n",
    "            writer.add_scalar('Train/EpochLoss', epoch_loss, epoch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1e0f069c9bdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tensorboard/test/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-af078ab8fa92>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, batch_size, optimizer, n_epochs, writer)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Anaconda/Miniconda/envs/DeepLearning/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-eb2425b229b4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, sequence_length, embedding_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, sequence_length, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshapeLSTMOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size*sequence_length, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Anaconda/Miniconda/envs/DeepLearning/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/Anaconda/Miniconda/envs/DeepLearning/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 559\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 6\n",
    "hidden_size = 512\n",
    "learning_rate = 1e-3\n",
    "seq_length = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = MusicalDataset(songs[musical_train_file], seq_lenght=seq_length)\n",
    "\n",
    "model = MusicalLSTMModel(dataset.getVocabSize(), embedding_dim=64, hidden_state_dim=hidden_size, \\\n",
    "                         rnn_units=dataset.getSequenceLength()).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "writer = SummaryWriter(\"tensorboard/test/\")\n",
    "train(model, dataset, batch_size, optimizer, 1, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = lambda a : a + 10\n",
    "print(test(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lenght = rnn_units = 11\n",
    "dataset = MusicalDataset(songs[musical_train_file], seq_lenght)\n",
    "vocab_size = dataset.getVocabSize()\n",
    "batch_size = 2\n",
    "dataloader = DataLoader(dataset, batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "model = MusicalLSTMModel(vocab_size, embedding_dim=256, hidden_state_dim=512, rnn_units=rnn_units)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dataloader))\n",
    "print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
    "h0 = torch.randn(rnn_units, seq_lenght, 512)\n",
    "c0 = torch.randn(rnn_units, seq_lenght, 512)\n",
    "states = (h0, c0)\n",
    "\n",
    "print(\"Prediction shape: \", pred.shape, \"# (batch_size * sequence_length, vocab_size)\")\n",
    "print(\"Hidden shape: \", hidden[0].shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "\n",
    "print(criterion(pred, y.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dataloader))\n",
    "print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
    "h0 = torch.randn(rnn_units, seq_lenght, 512)\n",
    "c0 = torch.randn(rnn_units, seq_lenght, 512)\n",
    "states = (h0, c0)\n",
    "pred, hidden = model(x, states)\n",
    "\n",
    "print(\"Prediction shape: \", pred.shape, \"# (batch_size * sequence_length, vocab_size)\")\n",
    "print(\"Hidden shape: \", hidden[0].shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Target shape: \", y.shape, \"# (batch_size, sequence_length)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_test = pred[:, 0:4, 0:2].permute(0,2,1)\n",
    "pred_test = pred[:, 0:4, 0:2]\n",
    "y_test = y[:, 0:4]\n",
    "\n",
    "print(\"Pred. shape: {}\".format(pred_test.shape))\n",
    "print(pred_test)\n",
    "print(\"Target shape: {}\".format(y_test.shape))\n",
    "print(y_test)\n",
    "y_test[:] = 1\n",
    "\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "print(criterion(pred_test, y_test.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "print(y.reshape(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = pred[:, 0:2, 0:2]\n",
    "y_test = y[:, 0:2]\n",
    "# print(pred_test.shape)\n",
    "# print(pred_test)\n",
    "\n",
    "print(\"-\"*10)\n",
    "logSoftmax = torch.nn.LogSoftmax(dim=2)\n",
    "soft = logSoftmax(pred_test)\n",
    "# print(soft.shape)\n",
    "# print(soft)\n",
    "print(y_test.shape)\n",
    "print(y_test)\n",
    "print(\"-\"*10)\n",
    "a, labels = logSoftmax(pred_test).max(dim=2)\n",
    "print(labels.shape)\n",
    "print(a.shape)\n",
    "print(y_test.reshape((2, -1)))\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "print(criterion(a, y_test.reshape(-1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, labels = pred.max(dim=2)\n",
    "print(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss = criterion(pred, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseCategoricalCrossEntropyWithLogits(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, dim=2):\n",
    "        super(SparseCategoricalCrossEntropyWithLogits, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.logSoftmax = torch.nn.LogSoftmax(dim=self.dim)\n",
    "        self.nllLoss = torch.nn.NLLLoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        _, labels = self.logSoftmax(pred).max(dim=self.dim)\n",
    "        return self.nllLoss(labels, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
